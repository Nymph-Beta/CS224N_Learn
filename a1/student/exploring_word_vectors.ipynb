{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HqK14JLSStR"
      },
      "source": [
        "# CS224N Assignment 1: Exploring Word Vectors (25 Points)\n",
        "### <font color='blue'> Due 4:30pm, Tue April 9th 2024</font>\n",
        "\n",
        "Welcome to CS224N! \n",
        "\n",
        "Before you start, make sure you **read the README.md** in the same directory as this notebook for important setup information. You need to install some Python libraries before you can successfully do this assignment. A lot of code is provided in this notebook, and we highly encourage you to read and understand it as part of the learning :)\n",
        "\n",
        "If you aren't super familiar with Python, Numpy, or Matplotlib, we recommend you check out the review session on Friday. The session will be recorded and the material will be made available on our [website](http://web.stanford.edu/class/cs224n/index.html#schedule). The CS231N Python/Numpy [tutorial](https://cs231n.github.io/python-numpy-tutorial/) is also a great resource.\n",
        "\n",
        "\n",
        "**Assignment Notes:** Please make sure to save the notebook as you go along. Submission Instructions are located at the bottom of the notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-27T08:04:19.343709Z",
          "start_time": "2024-03-27T08:04:15.222676Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AGQxROrSStf",
        "outputId": "45390a52-8c82-466d-dcf3-d5b355f14aa4"
      },
      "outputs": [],
      "source": [
        "# All Import Statements Defined Here\n",
        "# Note: Do not add to this list.\n",
        "# ----------------\n",
        "\n",
        "import sys\n",
        "# 确保使用 Python 3.x，且次版本号 >= 8\n",
        "assert sys.version_info[0] == 3\n",
        "assert sys.version_info[1] >= 8\n",
        "\n",
        "from platform import python_version\n",
        "# 进一步校验 Python 版本，不满足则报错提示升级\n",
        "assert int(python_version().split(\".\")[1]) >= 5, \"Please upgrade your Python version following the instructions in \\\n",
        "    the README.md file found in the same directory as this notebook. Your Python version is \" + python_version()\n",
        "\n",
        "from gensim.models import KeyedVectors  # gensim: 词向量工具库\n",
        "from gensim.test.utils import datapath\n",
        "import pprint                           # 用于格式化打印复杂数据结构\n",
        "import matplotlib.pyplot as plt         # 绘图库\n",
        "plt.rcParams['figure.figsize'] = [10, 5]  # 设置默认图表尺寸为 10×5 英寸\n",
        "\n",
        "from datasets import load_dataset\n",
        "imdb_dataset = load_dataset(\"stanfordnlp/imdb\")  # 加载 Stanford IMDB 影评数据集\n",
        "\n",
        "import re              # 正则表达式，用于文本预处理\n",
        "import numpy as np     # 数值计算核心库\n",
        "import random          # 随机数库\n",
        "import scipy as sp     # 科学计算库\n",
        "from sklearn.decomposition import TruncatedSVD # SVD降维\n",
        "from sklearn.decomposition import PCA # PCA降维\n",
        "\n",
        "START_TOKEN = '<START>'\n",
        "END_TOKEN = '<END>'\n",
        "NUM_SAMPLES = 150 # 使用150条评论\n",
        "\n",
        "# 设置随机种子\n",
        "np.random.seed(0)\n",
        "random.seed(0)\n",
        "# ----------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SICd5IedSSto"
      },
      "source": [
        "## Word Vectors\n",
        "\n",
        "Word Vectors are often used as a fundamental component for downstream NLP tasks, e.g. question answering, text generation, translation, etc., so it is important to build some intuitions as to their strengths and weaknesses. Here, you will explore two types of word vectors: those derived from *co-occurrence matrices*, and those derived via *GloVe*. \n",
        "\n",
        "**Note on Terminology:** The terms \"word vectors\" and \"word embeddings\" are often used interchangeably. The term \"embedding\" refers to the fact that we are encoding aspects of a word's meaning in a lower dimensional space. As [Wikipedia](https://en.wikipedia.org/wiki/Word_embedding) states, \"*conceptually it involves a mathematical embedding from a space with one dimension per word to a continuous vector space with a much lower dimension*\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Eug6AVrSStr"
      },
      "source": [
        "## Part 1: Count-Based Word Vectors (10 points)\n",
        "\n",
        "Most word vector models start from the following idea:\n",
        "\n",
        "*You shall know a word by the company it keeps ([Firth, J. R. 1957:11](https://en.wikipedia.org/wiki/John_Rupert_Firth))*\n",
        "\n",
        "Many word vector implementations are driven by the idea that similar words, i.e., (near) synonyms, will be used in similar contexts. As a result, similar words will often be spoken or written along with a shared subset of words, i.e., contexts. By examining these contexts, we can try to develop embeddings for our words. With this intuition in mind, many \"old school\" approaches to constructing word vectors relied on word counts. Here we elaborate upon one of those strategies, *co-occurrence matrices* (for more information, see [here](https://web.stanford.edu/~jurafsky/slp3/6.pdf) or [here](https://web.archive.org/web/20190530091127/https://medium.com/data-science-group-iitr/word-embedding-2d05d270b285))."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6uQ9-DVSSts"
      },
      "source": [
        "### Co-Occurrence\n",
        "\n",
        "A co-occurrence matrix counts how often things co-occur in some environment. Given some word $w_i$ occurring in the document, we consider the *context window* surrounding $w_i$. Supposing our fixed window size is $n$, then this is the $n$ preceding and $n$ subsequent words in that document, i.e. words $w_{i-n} \\dots w_{i-1}$ and $w_{i+1} \\dots w_{i+n}$. We build a *co-occurrence matrix* $M$, which is a symmetric word-by-word matrix in which $M_{ij}$ is the number of times $w_j$ appears inside $w_i$'s window among all documents.\n",
        "\n",
        "**Example: Co-Occurrence with Fixed Window of n=1**:\n",
        "\n",
        "Document 1: \"all that glitters is not gold\"\n",
        "\n",
        "Document 2: \"all is well that ends well\"\n",
        "\n",
        "\n",
        "|     *    | `<START>` | all | that | glitters | is   | not  | gold  | well | ends | `<END>` |\n",
        "|----------|-------|-----|------|----------|------|------|-------|------|------|-----|\n",
        "| `<START>`    | 0     | 2   | 0    | 0        | 0    | 0    | 0     | 0    | 0    | 0   |\n",
        "| all      | 2     | 0   | 1    | 0        | 1    | 0    | 0     | 0    | 0    | 0   |\n",
        "| that     | 0     | 1   | 0    | 1        | 0    | 0    | 0     | 1    | 1    | 0   |\n",
        "| glitters | 0     | 0   | 1    | 0        | 1    | 0    | 0     | 0    | 0    | 0   |\n",
        "| is       | 0     | 1   | 0    | 1        | 0    | 1    | 0     | 1    | 0    | 0   |\n",
        "| not      | 0     | 0   | 0    | 0        | 1    | 0    | 1     | 0    | 0    | 0   |\n",
        "| gold     | 0     | 0   | 0    | 0        | 0    | 1    | 0     | 0    | 0    | 1   |\n",
        "| well     | 0     | 0   | 1    | 0        | 1    | 0    | 0     | 0    | 1    | 1   |\n",
        "| ends     | 0     | 0   | 1    | 0        | 0    | 0    | 0     | 1    | 0    | 0   |\n",
        "| `<END>`      | 0     | 0   | 0    | 0        | 0    | 0    | 1     | 1    | 0    | 0   |\n",
        "\n",
        "In NLP, we commonly use `<START>` and `<END>` tokens to mark the beginning and end of sentences, paragraphs, or documents. These tokens are included in co-occurrence counts, encapsulating each document, for example: \"`<START>` All that glitters is not gold `<END>`\".\n",
        "\n",
        "The matrix rows (or columns) provide word vectors based on word-word co-occurrence, but they can be large. To reduce dimensionality, we employ Singular Value Decomposition (SVD), akin to PCA, selecting the top $k$ principal components. The SVD process decomposes the co-occurrence matrix $A$ into singular values in the diagonal $S$ matrix and new, shorter word vectors in $U_k$.\n",
        "\n",
        "This dimensionality reduction maintains semantic relationships; for instance, *doctor* and *hospital* will be closer than *doctor* and *dog*.\n",
        "\n",
        "For those unfamiliar with eigenvalues and SVD, a beginner-friendly introduction to SVD is available [here](https://davetang.org/file/Singular_Value_Decomposition_Tutorial.pdf). Additional resources for in-depth understanding include lectures [7](https://web.stanford.edu/class/cs168/l/l7.pdf), [8](http://theory.stanford.edu/~tim/s15/l/l8.pdf), and [9](https://web.stanford.edu/class/cs168/l/l9.pdf) of CS168, providing high-level treatment of these algorithms. For practical implementation, utilizing pre-programmed functions from Python packages like numpy, scipy, or sklearn is recommended. While applying full SVD to large corpora can be memory-intensive, scalable techniques such as Truncated SVD exist for extracting the top $k$ vector components efficiently."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7IKeK4xtSStv"
      },
      "source": [
        "### Plotting Co-Occurrence Word Embeddings\n",
        "\n",
        "Here, we will be using the Large Movie Review Dataset. This is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets. We provide a set of 25,000 highly polar movie reviews for training, and 25,000 for testing. There is additional unlabeled data for use as well. We provide a `read_corpus` function below that pulls out the text of a movie review from the dataset. The function also adds `<START>` and `<END>` tokens to each of the documents, and lowercases words. You do **not** have to perform any other kind of pre-processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-27T08:06:28.097673Z",
          "start_time": "2024-03-27T08:06:28.094138Z"
        },
        "id": "xwD2htUoSStw"
      },
      "outputs": [],
      "source": [
        "def read_corpus():\n",
        "    \"\"\" Read files from the Large Movie Review Dataset.\n",
        "        Params:\n",
        "            category (string): category name\n",
        "        Return:\n",
        "            list of lists, with words from each of the processed files\n",
        "    \"\"\"\n",
        "    # 从训练集中取前 NUM_SAMPLES 条评论的文本\n",
        "    files = imdb_dataset[\"train\"][\"text\"][:NUM_SAMPLES]\n",
        "    # return [[START_TOKEN] + [re.sub(r'[^\\w]', '', w.lower()) for w in f.split(\" \")] + [END_TOKEN] for f in files]\n",
        "    \n",
        "    res = []\n",
        "    for f in files:\n",
        "        words = []\n",
        "        for w in f.split(\" \"):\n",
        "            # 用正则去除所有非字母数字字符，并转为小写\n",
        "            words.append(re.sub(r'[^\\w]', '', w.lower()))\n",
        "        # 在每篇评论首尾分别添加 <START> 和 <END> 标记\n",
        "        res.append([START_TOKEN] + words + [END_TOKEN])\n",
        "    return res\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVLquFhjSStx"
      },
      "source": [
        "Let's have a look what these documents are like…."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-27T08:06:29.881790Z",
          "start_time": "2024-03-27T08:06:29.404708Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mC7B9Cb-SSty",
        "outputId": "a1861c4f-723a-4d99-98d9-5f5db3a92e7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['<START>', 'i', 'rented', 'i', 'am', 'curiousyellow', 'from', 'my', 'video', 'store', 'because',\n",
            "  'of', 'all', 'the', 'controversy', 'that', 'surrounded', 'it', 'when', 'it', 'was', 'first',\n",
            "  'released', 'in', '1967', 'i', 'also', 'heard', 'that', 'at', 'first', 'it', 'was', 'seized',\n",
            "  'by', 'us', 'customs', 'if', 'it', 'ever', 'tried', 'to', 'enter', 'this', 'country', 'therefore',\n",
            "  'being', 'a', 'fan', 'of', 'films', 'considered', 'controversial', 'i', 'really', 'had', 'to',\n",
            "  'see', 'this', 'for', 'myselfbr', 'br', 'the', 'plot', 'is', 'centered', 'around', 'a', 'young',\n",
            "  'swedish', 'drama', 'student', 'named', 'lena', 'who', 'wants', 'to', 'learn', 'everything',\n",
            "  'she', 'can', 'about', 'life', 'in', 'particular', 'she', 'wants', 'to', 'focus', 'her',\n",
            "  'attentions', 'to', 'making', 'some', 'sort', 'of', 'documentary', 'on', 'what', 'the', 'average',\n",
            "  'swede', 'thought', 'about', 'certain', 'political', 'issues', 'such', 'as', 'the', 'vietnam',\n",
            "  'war', 'and', 'race', 'issues', 'in', 'the', 'united', 'states', 'in', 'between', 'asking',\n",
            "  'politicians', 'and', 'ordinary', 'denizens', 'of', 'stockholm', 'about', 'their', 'opinions',\n",
            "  'on', 'politics', 'she', 'has', 'sex', 'with', 'her', 'drama', 'teacher', 'classmates', 'and',\n",
            "  'married', 'menbr', 'br', 'what', 'kills', 'me', 'about', 'i', 'am', 'curiousyellow', 'is',\n",
            "  'that', '40', 'years', 'ago', 'this', 'was', 'considered', 'pornographic', 'really', 'the', 'sex',\n",
            "  'and', 'nudity', 'scenes', 'are', 'few', 'and', 'far', 'between', 'even', 'then', 'its', 'not',\n",
            "  'shot', 'like', 'some', 'cheaply', 'made', 'porno', 'while', 'my', 'countrymen', 'mind', 'find',\n",
            "  'it', 'shocking', 'in', 'reality', 'sex', 'and', 'nudity', 'are', 'a', 'major', 'staple', 'in',\n",
            "  'swedish', 'cinema', 'even', 'ingmar', 'bergman', 'arguably', 'their', 'answer', 'to', 'good',\n",
            "  'old', 'boy', 'john', 'ford', 'had', 'sex', 'scenes', 'in', 'his', 'filmsbr', 'br', 'i', 'do',\n",
            "  'commend', 'the', 'filmmakers', 'for', 'the', 'fact', 'that', 'any', 'sex', 'shown', 'in', 'the',\n",
            "  'film', 'is', 'shown', 'for', 'artistic', 'purposes', 'rather', 'than', 'just', 'to', 'shock',\n",
            "  'people', 'and', 'make', 'money', 'to', 'be', 'shown', 'in', 'pornographic', 'theaters', 'in',\n",
            "  'america', 'i', 'am', 'curiousyellow', 'is', 'a', 'good', 'film', 'for', 'anyone', 'wanting',\n",
            "  'to', 'study', 'the', 'meat', 'and', 'potatoes', 'no', 'pun', 'intended', 'of', 'swedish',\n",
            "  'cinema', 'but', 'really', 'this', 'film', 'doesnt', 'have', 'much', 'of', 'a', 'plot', '<END>'],\n",
            " ['<START>', 'i', 'am', 'curious', 'yellow', 'is', 'a', 'risible', 'and', 'pretentious', 'steaming',\n",
            "  'pile', 'it', 'doesnt', 'matter', 'what', 'ones', 'political', 'views', 'are', 'because', 'this',\n",
            "  'film', 'can', 'hardly', 'be', 'taken', 'seriously', 'on', 'any', 'level', 'as', 'for', 'the',\n",
            "  'claim', 'that', 'frontal', 'male', 'nudity', 'is', 'an', 'automatic', 'nc17', 'that', 'isnt',\n",
            "  'true', 'ive', 'seen', 'rrated', 'films', 'with', 'male', 'nudity', 'granted', 'they', 'only',\n",
            "  'offer', 'some', 'fleeting', 'views', 'but', 'where', 'are', 'the', 'rrated', 'films', 'with',\n",
            "  'gaping', 'vulvas', 'and', 'flapping', 'labia', 'nowhere', 'because', 'they', 'dont', 'exist',\n",
            "  'the', 'same', 'goes', 'for', 'those', 'crappy', 'cable', 'shows', 'schlongs', 'swinging', 'in',\n",
            "  'the', 'breeze', 'but', 'not', 'a', 'clitoris', 'in', 'sight', 'and', 'those', 'pretentious',\n",
            "  'indie', 'movies', 'like', 'the', 'brown', 'bunny', 'in', 'which', 'were', 'treated', 'to', 'the',\n",
            "  'site', 'of', 'vincent', 'gallos', 'throbbing', 'johnson', 'but', 'not', 'a', 'trace', 'of',\n",
            "  'pink', 'visible', 'on', 'chloe', 'sevigny', 'before', 'crying', 'or', 'implying',\n",
            "  'doublestandard', 'in', 'matters', 'of', 'nudity', 'the', 'mentally', 'obtuse', 'should', 'take',\n",
            "  'into', 'account', 'one', 'unavoidably', 'obvious', 'anatomical', 'difference', 'between', 'men',\n",
            "  'and', 'women', 'there', 'are', 'no', 'genitals', 'on', 'display', 'when', 'actresses', 'appears',\n",
            "  'nude', 'and', 'the', 'same', 'cannot', 'be', 'said', 'for', 'a', 'man', 'in', 'fact', 'you',\n",
            "  'generally', 'wont', 'see', 'female', 'genitals', 'in', 'an', 'american', 'film', 'in',\n",
            "  'anything', 'short', 'of', 'porn', 'or', 'explicit', 'erotica', 'this', 'alleged',\n",
            "  'doublestandard', 'is', 'less', 'a', 'double', 'standard', 'than', 'an', 'admittedly',\n",
            "  'depressing', 'ability', 'to', 'come', 'to', 'terms', 'culturally', 'with', 'the', 'insides',\n",
            "  'of', 'womens', 'bodies', '<END>'],\n",
            " ['<START>', 'if', 'only', 'to', 'avoid', 'making', 'this', 'type', 'of', 'film', 'in', 'the',\n",
            "  'future', 'this', 'film', 'is', 'interesting', 'as', 'an', 'experiment', 'but', 'tells', 'no',\n",
            "  'cogent', 'storybr', 'br', 'one', 'might', 'feel', 'virtuous', 'for', 'sitting', 'thru', 'it',\n",
            "  'because', 'it', 'touches', 'on', 'so', 'many', 'important', 'issues', 'but', 'it', 'does', 'so',\n",
            "  'without', 'any', 'discernable', 'motive', 'the', 'viewer', 'comes', 'away', 'with', 'no', 'new',\n",
            "  'perspectives', 'unless', 'one', 'comes', 'up', 'with', 'one', 'while', 'ones', 'mind', 'wanders',\n",
            "  'as', 'it', 'will', 'invariably', 'do', 'during', 'this', 'pointless', 'filmbr', 'br', 'one',\n",
            "  'might', 'better', 'spend', 'ones', 'time', 'staring', 'out', 'a', 'window', 'at', 'a', 'tree',\n",
            "  'growingbr', 'br', '', '<END>']]\n",
            "corpus size:  290\n"
          ]
        }
      ],
      "source": [
        "# 读取语料，并打印前 3 篇评论内容和第 1 篇评论的单词数\n",
        "imdb_corpus = read_corpus()\n",
        "pprint.pprint(imdb_corpus[:3], compact=True, width=100)\n",
        "print(\"corpus size: \", len(imdb_corpus[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfa216H1SSt0"
      },
      "source": [
        "### Question 1.1: Implement `distinct_words` [code] (2 points)\n",
        "\n",
        "Write a method to work out the distinct words (word types) that occur in the corpus.\n",
        "\n",
        "You can use `for` loops to process the input `corpus` (a list of list of strings), but try using Python list comprehensions (which are generally faster). In particular, [this](https://coderwall.com/p/rcmaea/flatten-a-list-of-lists-in-one-line-in-python) may be useful to flatten a list of lists. If you're not familiar with Python list comprehensions in general, here's [more information](https://python-3-patterns-idioms-test.readthedocs.io/en/latest/Comprehensions.html).\n",
        "\n",
        "Your returned `corpus_words` should be sorted. You can use python's `sorted` function for this.\n",
        "\n",
        "You may find it useful to use [Python sets](https://www.w3schools.com/python/python_sets.asp) to remove duplicate words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "NjJABbVFSSt1"
      },
      "outputs": [],
      "source": [
        "def distinct_words(corpus):\n",
        "    \"\"\" Determine a list of distinct words for the corpus.\n",
        "        Params:\n",
        "            corpus (list of list of strings): corpus of documents\n",
        "        Return:\n",
        "            corpus_words (list of strings): sorted list of distinct words across the corpus\n",
        "            n_corpus_words (integer): number of distinct words across the corpus\n",
        "    \"\"\"\n",
        "    corpus_words = []\n",
        "    n_corpus_words = -1\n",
        "    \n",
        "    # ------------------\n",
        "    # Write your implementation here.\n",
        "    # 用列表推导式将二维列表展平，再用 set 去重，最后 sorted 排序\n",
        "    corpus_words = sorted(list(set(word for doc in corpus for word in doc)))\n",
        "    n_corpus_words = len(corpus_words)\n",
        "    \n",
        "    # ------------------\n",
        "\n",
        "    return corpus_words, n_corpus_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKfXBXySSSt3",
        "outputId": "8b49421a-1cff-4f10-fe4a-927f30570b59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Passed All Tests!\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# ---------------------\n",
        "# Run this sanity check\n",
        "# Note that this not an exhaustive check for correctness.\n",
        "# 运行此 cell 进行基本正确性检测（注意：这不是穷举测试）\n",
        "# ---------------------\n",
        "\n",
        "# Define toy corpus\n",
        "# 定义一个小型测试语料：两个短句子，首尾加上 <START>、<END>\n",
        "test_corpus = [\"{} All that glitters isn't gold {}\".format(START_TOKEN, END_TOKEN).split(\" \"), \"{} All's well that ends well {}\".format(START_TOKEN, END_TOKEN).split(\" \")]\n",
        "# 调用你实现的 distinct_words 函数，获取去重排序后的词列表和词数\n",
        "test_corpus_words, num_corpus_words = distinct_words(test_corpus)\n",
        "\n",
        "# Correct answers\n",
        "# 标准答案：手动去重并排序后的所有单词列表\n",
        "ans_test_corpus_words = sorted([START_TOKEN, \"All\", \"ends\", \"that\", \"gold\", \"All's\", \"glitters\", \"isn't\", \"well\", END_TOKEN])\n",
        "ans_num_corpus_words = len(ans_test_corpus_words)\n",
        "\n",
        "# Test correct number of words\n",
        "# 检验：去重后词的数量是否正确\n",
        "assert(num_corpus_words == ans_num_corpus_words), \"Incorrect number of distinct words. Correct: {}. Yours: {}\".format(ans_num_corpus_words, num_corpus_words)\n",
        "\n",
        "# Test correct words\n",
        "# 检验：去重排序后的词列表是否与标准答案一致\n",
        "assert (test_corpus_words == ans_test_corpus_words), \"Incorrect corpus_words.\\nCorrect: {}\\nYours:   {}\".format(str(ans_test_corpus_words), str(test_corpus_words))\n",
        "\n",
        "# Print Success\n",
        "# 全部通过则打印成功信息\n",
        "print (\"-\" * 80)\n",
        "print(\"Passed All Tests!\")\n",
        "print (\"-\" * 80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymDFJn_lSSt5"
      },
      "source": [
        "### Question 1.2: Implement `compute_co_occurrence_matrix` [code] (3 points)\n",
        "\n",
        "Write a method that constructs a co-occurrence matrix for a certain window-size $n$ (with a default of 4), considering words $n$ before and $n$ after the word in the center of the window. Here, we start to use `numpy (np)` to represent vectors, matrices, and tensors. If you're not familiar with NumPy, there's a NumPy tutorial in the second half of this cs231n [Python NumPy tutorial](http://cs231n.github.io/python-numpy-tutorial/).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "v8MIy3KDSSt6"
      },
      "outputs": [],
      "source": [
        "def compute_co_occurrence_matrix(corpus, window_size=4):\n",
        "    \"\"\" Compute co-occurrence matrix for the given corpus and window_size (default of 4).\n",
        "    \n",
        "        Note: Each word in a document should be at the center of a window. Words near edges will have a smaller\n",
        "              number of co-occurring words.\n",
        "              \n",
        "              For example, if we take the document \"<START> All that glitters is not gold <END>\" with window size of 4,\n",
        "              \"All\" will co-occur with \"<START>\", \"that\", \"glitters\", \"is\", and \"not\".\n",
        "    \n",
        "        Params:\n",
        "            corpus (list of list of strings): corpus of documents\n",
        "            window_size (int): size of context window\n",
        "        Return:\n",
        "            M (a symmetric numpy matrix of shape (number of unique words in the corpus , number of unique words in the corpus)): \n",
        "                Co-occurence matrix of word counts. \n",
        "                The ordering of the words in the rows/columns should be the same as the ordering of the words given by the distinct_words function.\n",
        "            word2ind (dict): dictionary that maps word to index (i.e. row/column number) for matrix M.\n",
        "    \"\"\"\n",
        "    words, n_words = distinct_words(corpus)\n",
        "    M = None\n",
        "    word2ind = {}\n",
        "    \n",
        "    # ------------------\n",
        "    # Write your implementation here.\n",
        "    # 初始化 n_words × n_words 的全零矩阵\n",
        "    M = np.zeros((n_words, n_words))\n",
        "    # 构建词到矩阵行/列索引的映射字典\n",
        "    word2ind = {word: i for i, word in enumerate(words)}\n",
        "    \n",
        "    for doc in corpus:\n",
        "        for i in range(len(doc)):\n",
        "            center_word = doc[i]            # 当前中心词\n",
        "            center_word_idx = word2ind[center_word]\n",
        "\n",
        "            # 遍历中心词左右 window_size 范围内的上下文词\n",
        "            for j in range(max(0, i - window_size), min(len(doc), i + window_size + 1)):\n",
        "                if j != i:  # 跳过中心词本身\n",
        "                    context_word = doc[j]\n",
        "                    context_word_idx = word2ind[context_word]\n",
        "                    # 对应位置的共现计数 +1\n",
        "                    M[center_word_idx, context_word_idx] += 1\n",
        "    # ------------------\n",
        "\n",
        "    return M, word2ind"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-6ID1qhSSt7",
        "outputId": "f4f1bccb-06a8-4bb6-ec80-f2b6201b2645"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Passed All Tests!\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# ---------------------\n",
        "# Run this sanity check\n",
        "# Note that this is not an exhaustive check for correctness.\n",
        "# 运行此 cell 进行基本正确性检测（注意：这不是穷举测试）\n",
        "# ---------------------\n",
        "\n",
        "# Define toy corpus and get student's co-occurrence matrix\n",
        "# 定义测试语料，用窗口大小 1 构建共现矩阵\n",
        "test_corpus = [\"{} All that glitters isn't gold {}\".format(START_TOKEN, END_TOKEN).split(\" \"), \"{} All's well that ends well {}\".format(START_TOKEN, END_TOKEN).split(\" \")]\n",
        "M_test, word2ind_test = compute_co_occurrence_matrix(test_corpus, window_size=1)\n",
        "\n",
        "# Correct M and word2ind\n",
        "# 标准答案：窗口大小为 1 时的正确共现矩阵\n",
        "M_test_ans = np.array( \n",
        "    [[0., 0., 0., 0., 0., 0., 1., 0., 0., 1.,],\n",
        "     [0., 0., 1., 1., 0., 0., 0., 0., 0., 0.,],\n",
        "     [0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,],\n",
        "     [0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,],\n",
        "     [0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,],\n",
        "     [0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,],\n",
        "     [1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,],\n",
        "     [0., 0., 0., 0., 0., 1., 1., 0., 0., 0.,],\n",
        "     [0., 0., 1., 0., 1., 1., 0., 0., 0., 1.,],\n",
        "     [1., 0., 0., 1., 1., 0., 0., 0., 1., 0.,]]\n",
        ")\n",
        "# 标准答案：排序后的词列表和对应的索引字典\n",
        "ans_test_corpus_words = sorted([START_TOKEN, \"All\", \"ends\", \"that\", \"gold\", \"All's\", \"glitters\", \"isn't\", \"well\", END_TOKEN])\n",
        "word2ind_ans = dict(zip(ans_test_corpus_words, range(len(ans_test_corpus_words))))\n",
        "\n",
        "# Test correct word2ind\n",
        "# 检验：word2ind 映射字典是否正确\n",
        "assert (word2ind_ans == word2ind_test), \"Your word2ind is incorrect:\\nCorrect: {}\\nYours: {}\".format(word2ind_ans, word2ind_test)\n",
        "\n",
        "# Test correct M shape\n",
        "# 检验：共现矩阵的维度（shape）是否正确\n",
        "assert (M_test.shape == M_test_ans.shape), \"M matrix has incorrect shape.\\nCorrect: {}\\nYours: {}\".format(M_test.shape, M_test_ans.shape)\n",
        "\n",
        "# Test correct M values\n",
        "# 逐元素检验：共现矩阵中每个位置的计数值是否正确\n",
        "for w1 in word2ind_ans.keys():\n",
        "    idx1 = word2ind_ans[w1]\n",
        "    for w2 in word2ind_ans.keys():\n",
        "        idx2 = word2ind_ans[w2]\n",
        "        student = M_test[idx1, idx2]\n",
        "        correct = M_test_ans[idx1, idx2]\n",
        "        if student != correct:\n",
        "            print(\"Correct M:\")\n",
        "            print(M_test_ans)\n",
        "            print(\"Your M: \")\n",
        "            print(M_test)\n",
        "            raise AssertionError(\"Incorrect count at index ({}, {})=({}, {}) in matrix M. Yours has {} but should have {}.\".format(idx1, idx2, w1, w2, student, correct))\n",
        "\n",
        "# Print Success\n",
        "# 全部通过则打印成功信息\n",
        "print (\"-\" * 80)\n",
        "print(\"Passed All Tests!\")\n",
        "print (\"-\" * 80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-nyJnAASSt9"
      },
      "source": [
        "### Question 1.3: Implement `reduce_to_k_dim` [code] (1 point)\n",
        "\n",
        "Construct a method that performs dimensionality reduction on the matrix to produce k-dimensional embeddings. Use SVD to take the top k components and produce a new matrix of k-dimensional embeddings. \n",
        "\n",
        "**Note:** All of numpy, scipy, and scikit-learn (`sklearn`) provide *some* implementation of SVD, but only scipy and sklearn provide an implementation of Truncated SVD, and only sklearn provides an efficient randomized algorithm for calculating large-scale Truncated SVD. So please use [sklearn.decomposition.TruncatedSVD](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "truGMjifSSt9"
      },
      "outputs": [],
      "source": [
        "def reduce_to_k_dim(M, k=2):\n",
        "    \"\"\" Reduce a co-occurence count matrix of dimensionality (num_corpus_words, num_corpus_words)\n",
        "        to a matrix of dimensionality (num_corpus_words, k) using the following SVD function from Scikit-Learn:\n",
        "            - http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html\n",
        "    \n",
        "        Params:\n",
        "            M (numpy matrix of shape (number of unique words in the corpus , number of unique words in the corpus)): co-occurence matrix of word counts\n",
        "            k (int): embedding size of each word after dimension reduction\n",
        "        Return:\n",
        "            M_reduced (numpy matrix of shape (number of corpus words, k)): matrix of k-dimensioal word embeddings.\n",
        "                    In terms of the SVD from math class, this actually returns U * S\n",
        "    \"\"\"    \n",
        "    n_iters = 10    # Use this parameter in your call to `TruncatedSVD`\n",
        "                    # 迭代次数，传给 TruncatedSVD 以提高近似精度\n",
        "    M_reduced = None\n",
        "    print(\"Running Truncated SVD over %i words...\" % (M.shape[0]))\n",
        "    \n",
        "    # ------------------\n",
        "    # Write your implementation here.\n",
        "    # 使用截断 SVD 将矩阵从 (词数, 词数) 降维到 (词数, k)\n",
        "    # fit_transform 返回的是 U * S，即降维后的词向量矩阵\n",
        "    M_reduced = TruncatedSVD(n_components=k, n_iter=n_iters).fit_transform(M)\n",
        "    \n",
        "    # ------------------\n",
        "\n",
        "    print(\"Done.\")\n",
        "    return M_reduced"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pqKuqvhSSt-",
        "outputId": "7d147bd2-9916-4226-d936-43ce795006cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running Truncated SVD over 10 words...\n",
            "Done.\n",
            "--------------------------------------------------------------------------------\n",
            "Passed All Tests!\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# ---------------------\n",
        "# Run this sanity check\n",
        "# Note that this is not an exhaustive check for correctness \n",
        "# In fact we only check that your M_reduced has the right dimensions.\n",
        "# 运行此 cell 进行基本检测（此处只检验降维后矩阵的维度是否正确）\n",
        "# ---------------------\n",
        "\n",
        "# Define toy corpus and run student code\n",
        "# 用测试语料构建共现矩阵，然后调用你的降维函数\n",
        "test_corpus = [\"{} All that glitters isn't gold {}\".format(START_TOKEN, END_TOKEN).split(\" \"), \"{} All's well that ends well {}\".format(START_TOKEN, END_TOKEN).split(\" \")]\n",
        "M_test, word2ind_test = compute_co_occurrence_matrix(test_corpus, window_size=1)\n",
        "M_test_reduced = reduce_to_k_dim(M_test, k=2)\n",
        "\n",
        "# Test proper dimensions\n",
        "# 检验：降维后的矩阵应有 10 行（10 个不同的词）、2 列（k=2 维）\n",
        "assert (M_test_reduced.shape[0] == 10), \"M_reduced has {} rows; should have {}\".format(M_test_reduced.shape[0], 10)\n",
        "assert (M_test_reduced.shape[1] == 2), \"M_reduced has {} columns; should have {}\".format(M_test_reduced.shape[1], 2)\n",
        "\n",
        "# Print Success\n",
        "# 全部通过则打印成功信息\n",
        "print (\"-\" * 80)\n",
        "print(\"Passed All Tests!\")\n",
        "print (\"-\" * 80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apZknsLoSSt_"
      },
      "source": [
        "### Question 1.4: Implement `plot_embeddings` [code] (1 point)\n",
        "\n",
        "Here you will write a function to plot a set of 2D vectors in 2D space. For graphs, we will use Matplotlib (`plt`).\n",
        "\n",
        "For this example, you may find it useful to adapt [this code](http://web.archive.org/web/20190924160434/https://www.pythonmembers.club/2018/05/08/matplotlib-scatter-plot-annotate-set-text-at-label-each-point/). In the future, a good way to make a plot is to look at [the Matplotlib gallery](https://matplotlib.org/gallery/index.html), find a plot that looks somewhat like what you want, and adapt the code they give."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "dDcCZE5lSSuA"
      },
      "outputs": [],
      "source": [
        "def plot_embeddings(M_reduced, word2ind, words):\n",
        "    \"\"\" Plot in a scatterplot the embeddings of the words specified in the list \"words\".\n",
        "        NOTE: do not plot all the words listed in M_reduced / word2ind.\n",
        "        Include a label next to each point.\n",
        "        \n",
        "        Params:\n",
        "            M_reduced (numpy matrix of shape (number of unique words in the corpus , 2)): matrix of 2-dimensioal word embeddings\n",
        "            word2ind (dict): dictionary that maps word to indices for matrix M\n",
        "            words (list of strings): words whose embeddings we want to visualize\n",
        "    \"\"\"\n",
        "\n",
        "    # ------------------\n",
        "    # Write your implementation here.\n",
        "    for w in words:\n",
        "        w_idx = word2ind[w]               # 获取该词在矩阵中的行索引\n",
        "        # 在 2D 平面上画出该词的坐标点（红色 × 标记）\n",
        "        plt.scatter(M_reduced[w_idx, 0], M_reduced[w_idx, 1], marker='x', color='red')\n",
        "        # 在坐标点旁边标注单词文本\n",
        "        plt.annotate(w, (M_reduced[w_idx, 0], M_reduced[w_idx, 1]))\n",
        "    \n",
        "    # ------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "id": "gHxOMWPxSSuB",
        "outputId": "565711fc-02ea-43cb-daa5-8b8bb310cdda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Outputted Plot:\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# ---------------------\n",
        "# Run this sanity check\n",
        "# Note that this is not an exhaustive check for correctness.\n",
        "# The plot produced should look like the included file question_1.4_test.png \n",
        "# 运行此 cell 测试你的 plot_embeddings 函数\n",
        "# 生成的图应与附件中的 question_1.4_test.png 一致\n",
        "# ---------------------\n",
        "\n",
        "print (\"-\" * 80)\n",
        "print (\"Outputted Plot:\")\n",
        "\n",
        "# 构造 5 个测试用的 2D 坐标点和对应的词-索引映射\n",
        "M_reduced_plot_test = np.array([[1, 1], [-1, -1], [1, -1], [-1, 1], [0, 0]])\n",
        "word2ind_plot_test = {'test1': 0, 'test2': 1, 'test3': 2, 'test4': 3, 'test5': 4}\n",
        "words = ['test1', 'test2', 'test3', 'test4', 'test5']\n",
        "# 调用你实现的绘图函数，将 5 个测试词在 2D 平面上可视化\n",
        "plot_embeddings(M_reduced_plot_test, word2ind_plot_test, words)\n",
        "\n",
        "print (\"-\" * 80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpBzYs2hSSuC"
      },
      "source": [
        "### Question 1.5: Co-Occurrence Plot Analysis [written] (3 points)\n",
        "\n",
        "Now we will put together all the parts you have written! We will compute the co-occurrence matrix with fixed window of 4 (the default window size), over the Large Movie Review corpus. Then we will use TruncatedSVD to compute 2-dimensional embeddings of each word. TruncatedSVD returns U\\*S, so we need to normalize the returned vectors, so that all the vectors will appear around the unit circle (therefore closeness is directional closeness). **Note**: The line of code below that does the normalizing uses the NumPy concept of *broadcasting*. If you don't know about broadcasting, check out\n",
        "[Computation on Arrays: Broadcasting by Jake VanderPlas](https://jakevdp.github.io/PythonDataScienceHandbook/02.05-computation-on-arrays-broadcasting.html).\n",
        "\n",
        "Run the below cell to produce the plot. It can take up to a few minutes to run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "7L1Uk50mSSuD",
        "outputId": "35ae3e41-07c8-421b-e75c-dcbeaa4fb015"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running Truncated SVD over 5880 words...\n",
            "Done.\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# -----------------------------\n",
        "# Run This Cell to Produce Your Plot\n",
        "# 运行此 cell 生成 Q1.5 的词向量可视化图\n",
        "# ------------------------------\n",
        "imdb_corpus = read_corpus()                                                         # 读取语料\n",
        "M_co_occurrence, word2ind_co_occurrence = compute_co_occurrence_matrix(imdb_corpus)  # 构建共现矩阵\n",
        "M_reduced_co_occurrence = reduce_to_k_dim(M_co_occurrence, k=2)                     # SVD 降维到 2 维\n",
        "\n",
        "# Rescale (normalize) the rows to make them each of unit-length\n",
        "# 将每个 2D 向量归一化为单位长度，使所有点落在单位圆上，便于比较方向\n",
        "M_lengths = np.linalg.norm(M_reduced_co_occurrence, axis=1)\n",
        "M_normalized = M_reduced_co_occurrence / M_lengths[:, np.newaxis] # broadcasting\n",
        "\n",
        "# 选定要可视化的 10 个词\n",
        "words = ['movie', 'book', 'mysterious', 'story', 'fascinating', 'good', 'interesting', 'large', 'massive', 'huge']\n",
        "\n",
        "plot_embeddings(M_normalized, word2ind_co_occurrence, words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtOd40JTSSuE"
      },
      "source": [
        "**Verify that your figure matches \"question_1.5.png\" in the assignment zip. If not, use the figure in \"question_1.5.png\" to answer the next two questions.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciXWGMvRSSuE"
      },
      "source": [
        "a. Find at least two groups of words that cluster together in 2-dimensional embedding space. Give an explanation for each cluster you observe."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLU7o3HESSuF"
      },
      "source": [
        "#### <font color=\"red\">Write your answer here.</font>\n",
        "1. \"book\" 和 \"movie\"：这两个词在图中几乎重叠在一起（大约在 x=0.97~0.98, y=0.25~0.26 的位置）。原因是它们都属于叙事媒体类型，在 IMDB 电影评论语料中，人们经常同时讨论电影和原著书籍（比如改编作品的对比），因此它们共享大量相似的上下文词汇。\"story\" 也在它们附近，进一步印证了这一语义关联。\n",
        "2. \"fascinating\"、\"good\" 和 \"interesting\"：这三个词紧密聚在图的右侧（大约在 x=0.99~1.00, y=0.13~0.18 的位置）。它们都是正面评价性形容词，在电影评论中经常用于表达对电影的正面感受（如 \"a good/fascinating/interesting film\"），共享非常相似的上下文窗口"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3H-tyA9RSSuF"
      },
      "source": [
        "b. What doesn't cluster together that you might think should have? Describe at least two examples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NG2j9J4SSuG"
      },
      "source": [
        "#### <font color=\"red\">Write your answer here.</font>\n",
        "1. “large\"、\"massive\" 和 \"huge\"：这三个词都是表示\"大\"的近义词，语义上非常接近，理应聚在一起。但从图中可以看到，\"massive\" 在左上角（~0.85, 0.52），\"large\" 在中间偏上（~0.93, 0.36），而 \"huge\" 却跑到了右下方（~1.00, -0.02），三者分布非常分散。这可能是因为在只有 150 条评论的小语料中，这些词的出现频率较低且上下文各不相同，导致共现统计不够稳定，SVD 降维后无法准确捕捉它们之间的近义关系。\n",
        "2. \"mysterious\" 和 \"fascinating\"：这两个词在语义上有关联——都可以用来描述引人入胜的、令人好奇的事物。但在图中，\"mysterious\" 孤立在底部（~0.97, -0.24），远离 \"fascinating\"（~0.99, 0.18）。这是因为基于共现矩阵的方法依赖局部上下文窗口，\"mysterious\" 更多出现在描述剧情/角色的语境中，而 \"fascinating\" 更多出现在评价性语句中，两者的共现模式差异较大。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_h0OzAaRSSuI"
      },
      "source": [
        "## Part 2: Prediction-Based Word Vectors (15 points)\n",
        "\n",
        "As discussed in class, more recently prediction-based word vectors have demonstrated better performance, such as word2vec and GloVe (which also utilizes the benefit of counts). Here, we shall explore the embeddings produced by GloVe. Please revisit the class notes and lecture slides for more details on the word2vec and GloVe algorithms. If you're feeling adventurous, challenge yourself and try reading [GloVe's original paper](https://nlp.stanford.edu/pubs/glove.pdf).\n",
        "\n",
        "Then run the following cells to load the GloVe vectors into memory. **Note**: If this is your first time to run these cells, i.e. download the embedding model, it will take a couple minutes to run. If you've run these cells before, rerunning them will load the model without redownloading it, which will take about 1 to 2 minutes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3kwvdksSSuI",
        "outputId": "736a4672-4b59-4c2e-d6e6-b16e4548db30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded vocab size 400000\n"
          ]
        }
      ],
      "source": [
        "# 过 gensim 库下载并加载 glove-wiki-gigaword-200 模型。\n",
        "# 这是在 Wikipedia + Gigaword 语料上训练的 GloVe 向量，词汇量约 40 万个词，每个词的向量维度是 200 维。\n",
        "# 返回的 wv_from_bin 是一个 gensim 的 KeyedVectors 对象，可以用它来查询词向量、计算相似度等。\n",
        "def load_embedding_model():\n",
        "    \"\"\" Load GloVe Vectors\n",
        "        Return:\n",
        "            wv_from_bin: All 400000 embeddings, each length 200\n",
        "    \"\"\"\n",
        "    import gensim.downloader as api\n",
        "    wv_from_bin = api.load(\"glove-wiki-gigaword-200\")\n",
        "    print(\"Loaded vocab size %i\" % len(list(wv_from_bin.index_to_key)))\n",
        "    return wv_from_bin\n",
        "wv_from_bin = load_embedding_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egIeG1RTSSuK"
      },
      "source": [
        "#### Note: If you are receiving a \"reset by peer\" error, rerun the cell to restart the download. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rH9gWJWpSSuL"
      },
      "source": [
        "### Reducing dimensionality of Word Embeddings\n",
        "Let's directly compare the GloVe embeddings to those of the co-occurrence matrix. In order to avoid running out of memory, we will work with a sample of 40000 GloVe vectors instead.\n",
        "Run the following cells to:\n",
        "\n",
        "1. Put 40000 Glove vectors into a matrix M\n",
        "2. Run `reduce_to_k_dim` (your Truncated SVD function) to reduce the vectors from 200-dimensional to 2-dimensional.\n",
        "\n",
        "### 降低词嵌入的维度\n",
        "让我们直接比较 GloVe 嵌入与共现矩阵的嵌入。为了避免内存不足，我们将使用 40000 个 GloVe 向量的样本进行处理。\n",
        "运行以下单元格以：\n",
        "\n",
        "1. 将 40000 个 GloVe 向量放入矩阵 M 中\n",
        "2. 运行 `reduce_to_k_dim`（你的截断奇异值分解函数），将向量从 200 维降至 2 维。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "0PROUu_-SSuL"
      },
      "outputs": [],
      "source": [
        "def get_matrix_of_vectors(wv_from_bin, required_words):\n",
        "    \"\"\" Put the GloVe vectors into a matrix M.\n",
        "        Param:\n",
        "            wv_from_bin: KeyedVectors object; the 400000 GloVe vectors loaded from file\n",
        "        Return:\n",
        "            M: numpy matrix shape (num words, 200) containing the vectors\n",
        "            word2ind: dictionary mapping each word to its row number in M\n",
        "    \"\"\"\n",
        "    import random\n",
        "    # wv_from_bin.index_to_key 是 gensim 中存储所有词的列表（约 40 万个词），按词频从高到低排列。\n",
        "    words = list(wv_from_bin.index_to_key) \n",
        "    print(\"Shuffling words ...\")\n",
        "    # 设置随机种子，确保每次打乱顺序相同\n",
        "    random.seed(225)\n",
        "    # 打乱词顺序\n",
        "    random.shuffle(words)\n",
        "    print(\"Putting %i words into word2ind and matrix M...\" % len(words))\n",
        "    # 创建词到索引的映射字典\n",
        "    word2ind = {}\n",
        "    # 创建一个空列表，用于存储词向量\n",
        "    M = []\n",
        "    # 当前索引\n",
        "    curInd = 0\n",
        "    # 遍历所有词\n",
        "    for w in words:\n",
        "        try:\n",
        "            # 取出该词的 200 维向量，追加到列表 M 中。\n",
        "            M.append(wv_from_bin.get_vector(w))\n",
        "            # 将该词的索引 curInd 存入字典 word2ind 中。\n",
        "            word2ind[w] = curInd\n",
        "            # 索引 curInd 加 1。\n",
        "            curInd += 1\n",
        "        except KeyError:\n",
        "            continue\n",
        "    # 遍历 required_words 列表中的词\n",
        "    # required_words 是调用者传入的一组必须出现在矩阵中的词\n",
        "    for w in required_words:\n",
        "        # 如果词 w 在 words 列表中，则跳过\n",
        "        if w in words:\n",
        "            continue\n",
        "        try:\n",
        "            M.append(wv_from_bin.get_vector(w))\n",
        "            word2ind[w] = curInd\n",
        "            curInd += 1\n",
        "        except KeyError:\n",
        "            continue\n",
        "    # 将列表 M 转换为 numpy 数组，把它们堆叠成一个 shape 为 (约400000, 200) 的二维 numpy 矩阵。\n",
        "    # 矩阵 M 的每一行对应一个词的 200 维向量。\n",
        "    M = np.stack(M)\n",
        "    print(\"Done.\")\n",
        "    return M, word2ind"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpgM0M-hSSuM",
        "outputId": "b0989be9-8e11-45d8-8ba9-47297a990760"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shuffling words ...\n",
            "Putting 400000 words into word2ind and matrix M...\n",
            "Done.\n",
            "Running Truncated SVD over 400000 words...\n",
            "Done.\n"
          ]
        }
      ],
      "source": [
        "# -----------------------------------------------------------------\n",
        "# Run Cell to Reduce 200-Dimensional Word Embeddings to k Dimensions\n",
        "# Note: This should be quick to run\n",
        "# -----------------------------------------------------------------\n",
        "M, word2ind = get_matrix_of_vectors(wv_from_bin, words)\n",
        "# 调用 reduce_to_k_dim 函数，将 200 维的词向量降维到 2 维。\n",
        "# 降维后每个词只有 2 个分量，可以在 2D 平面上画出来。\n",
        "M_reduced = reduce_to_k_dim(M, k=2)\n",
        "\n",
        "# Rescale (normalize) the rows to make them each of unit-length\n",
        "# 将降维后的每个词向量归一化，使它们的长度为 1。\n",
        "# 归一化后，每个词向量在 2D 平面上表示为一个单位向量，便于比较它们之间的方向。\n",
        "M_lengths = np.linalg.norm(M_reduced, axis=1)\n",
        "M_reduced_normalized = M_reduced / M_lengths[:, np.newaxis] # broadcasting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_46FYMJSSuN"
      },
      "source": [
        "**Note: If you are receiving out of memory issues on your local machine, try closing other applications to free more memory on your device. You may want to try restarting your machine so that you can free up extra memory. Then immediately run the jupyter notebook and see if you can load the word vectors properly. If you still have problems with loading the embeddings onto your local machine after this, please go to office hours or contact course staff.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAFrU8ahSSuO"
      },
      "source": [
        "### Question 2.1: GloVe Plot Analysis [written] (3 points)\n",
        "\n",
        "Run the cell below to plot the 2D GloVe embeddings for `['movie', 'book', 'mysterious', 'story', 'fascinating', 'good', 'interesting', 'large', 'massive', 'huge']`.\n",
        "\n",
        "运行下方单元格，绘制`['movie', 'book', 'mysterious', 'story', 'fascinating', 'good', 'interesting', 'large', 'massive', 'huge']`的二维 GloVe 嵌入图。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "9kHRkjz6SSuO",
        "outputId": "fbe0f8af-ea5e-456d-8d75-b9ad0caaa5fc",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "words = ['movie', 'book', 'mysterious', 'story', 'fascinating', 'good', 'interesting', 'large', 'massive', 'huge']\n",
        "\n",
        "plot_embeddings(M_reduced_normalized, word2ind, words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Verify that your figure matches \"question_2.1.png\" in the assignment zip. If not, use the figure in \"question_2.1.png\" (and the figure in \"question_1.5.png\", if applicable) to answer the next two questions.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOnrMZkzSSuP"
      },
      "source": [
        "a. What is one way the plot is different from the one generated earlier from the co-occurrence matrix? What is one way it's similar?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KC4PTQoSSuQ"
      },
      "source": [
        "#### <font color=\"red\">Write your answer here.</font>\n",
        "\n",
        "1. 不同：\n",
        "question_1.5（共现矩阵）中，\"large\"、\"massive\"、\"huge\" 这三个\"大\"的近义词——它们分散在图的不同位置（massive 在左下角远离其他词，large 在中间偏下，huge 在右上角）。而在 question_2.1（GloVe）中，\"huge\"、\"large\" 靠得比较近（都在中间区域），虽然 \"massive\" 稍远一些，但三者的聚集程度明显比共现矩阵图要好。\n",
        "说明GloVe 更好地捕捉了同义词之间的语义关系。\n",
        "\n",
        "2. 相似：\n",
        "在两张图中，\"book\"、\"story\"、\"movie\" 这三个叙事媒体类的词都彼此靠近，形成一个聚类。这说明无论是共现矩阵方法还是 GloVe，都能识别出这几个词在语义上的关联。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNDY5puZSSuQ"
      },
      "source": [
        "b. Why might the GloVe plot (question_2.1.png) differ from the plot generated earlier from the co-occurrence matrix (question_1.5.png)?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-cWAvi8SSuR"
      },
      "source": [
        "#### <font color=\"red\">Write your answer here.</font>\n",
        "\n",
        "> 1. 训练语料不同：共现矩阵是在仅 150 条 IMDB 评论上构建的（很小的语料），而 GloVe 是在 Wikipedia + Gigaword（数十亿词的大规模语料）上训练的。语料规模差异巨大，直接影响词向量质量。\n",
        "> 2. 算法不同：共现矩阵 + SVD 是一种简单的基于计数的方法；GloVe 则通过优化一个对数双线性回归目标函数来学习向量，能更好地捕捉词与词之间的语义关系（不仅仅是局部共现计数）。\n",
        "> 3. 向量维度不同：共现矩阵原始维度等于词汇表大小（约 5880），SVD 降到 2 维损失很大；GloVe 原始维度只有 200，降到 2 维时信息保留得更好"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nA8oIbjjSSuS"
      },
      "source": [
        "### Cosine Similarity\n",
        "Now that we have word vectors, we need a way to quantify the similarity between individual words, according to these vectors. One such metric is cosine-similarity. We will be using this to find words that are \"close\" and \"far\" from one another.\n",
        "\n",
        "We can think of n-dimensional vectors as points in n-dimensional space. If we take this perspective [L1](http://mathworld.wolfram.com/L1-Norm.html) and [L2](http://mathworld.wolfram.com/L2-Norm.html) Distances help quantify the amount of space \"we must travel\" to get between these two points. Another approach is to examine the angle between two vectors. From trigonometry we know that:\n",
        "\n",
        "<img src=\"./imgs/inner_product.png\" width=20% style=\"float: center;\"></img>\n",
        "\n",
        "Instead of computing the actual angle, we can leave the similarity in terms of $similarity = cos(\\Theta)$. Formally the [Cosine Similarity](https://en.wikipedia.org/wiki/Cosine_similarity) $s$ between two vectors $p$ and $q$ is defined as:\n",
        "\n",
        "$$s = \\frac{p \\cdot q}{||p|| ||q||}, \\textrm{ where } s \\in [-1, 1] $$ "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFfCOLUsSSuS"
      },
      "source": [
        "### Question 2.2: Words with Multiple Meanings (1.5 points) [code + written] \n",
        "Polysemes and homonyms are words that have more than one meaning (see this [wiki page](https://en.wikipedia.org/wiki/Polysemy) to learn more about the difference between polysemes and homonyms ). Find a word with *at least two different meanings* such that the top-10 most similar words (according to cosine similarity) contain related words from *both* meanings. For example, \"leaves\" has both \"go_away\" and \"a_structure_of_a_plant\" meaning in the top 10, and \"scoop\" has both \"handed_waffle_cone\" and \"lowdown\". You will probably need to try several polysemous or homonymic words before you find one. \n",
        "\n",
        "Please state the word you discover and the multiple meanings that occur in the top 10. Why do you think many of the polysemous or homonymic words you tried didn't work (i.e. the top-10 most similar words only contain **one** of the meanings of the words)?\n",
        "\n",
        "**Note**: You should use the `wv_from_bin.most_similar(word)` function to get the top 10 most similar words. This function ranks all other words in the vocabulary with respect to their cosine similarity to the given word. For further assistance, please check the __[GenSim documentation](https://radimrehurek.com/gensim/models/keyedvectors.html#gensim.models.keyedvectors.FastTextKeyedVectors.most_similar)__."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAr09U-xSSuT",
        "outputId": "da8adff7-c61e-43a0-8f4b-66084b4a66b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('mice', 0.6580958962440491), ('keyboard', 0.5548278093338013), ('rat', 0.5433949828147888), ('rabbit', 0.5192376971244812), ('cat', 0.5077415704727173), ('cursor', 0.5058691501617432), ('trackball', 0.5048902630805969), ('joystick', 0.49841049313545227), ('mickey', 0.47242844104766846), ('clicks', 0.4722806215286255)]\n",
            "[('bats', 0.691724419593811), ('batting', 0.6160588264465332), ('balls', 0.5692734122276306), ('batted', 0.5530908107757568), ('toss', 0.5506128668785095), ('wicket', 0.5495278835296631), ('pitch', 0.5489361882209778), ('bowled', 0.5452010631561279), ('hitter', 0.5353438854217529), ('batsman', 0.5348091125488281)]\n",
            "[('banks', 0.7625691294670105), ('banking', 0.6818838119506836), ('central', 0.6283639073371887), ('financial', 0.6166563034057617), ('credit', 0.6049750447273254), ('lending', 0.5980608463287354), ('monetary', 0.5963003039360046), ('bankers', 0.5913101434707642), ('loans', 0.5802939534187317), ('investment', 0.5740203261375427)]\n",
            "[('summer', 0.8025314211845398), ('autumn', 0.7510949969291687), ('winter', 0.7315691113471985), ('fall', 0.6582662463188171), ('beginning', 0.6507853269577026), ('starting', 0.6281813979148865), ('year', 0.6142006516456604), ('start', 0.5800090432167053), ('next', 0.5771185159683228), ('during', 0.5726782083511353)]\n",
            "[('iphone', 0.6271388530731201), ('microsoft', 0.6061939001083374), ('intel', 0.599233090877533), ('macintosh', 0.5989753603935242), ('ipod', 0.5908078551292419), ('ibm', 0.5888804793357849), ('ipad', 0.5876859426498413), ('software', 0.5711662173271179), ('google', 0.5554560422897339), ('itunes', 0.5478185415267944)]\n"
          ]
        }
      ],
      "source": [
        "# ------------------\n",
        "# Write your implementation here.\n",
        "print(wv_from_bin.most_similar(\"mouse\"))\n",
        "print(wv_from_bin.most_similar(\"bat\"))\n",
        "print(wv_from_bin.most_similar(\"bank\"))\n",
        "print(wv_from_bin.most_similar(\"spring\"))\n",
        "print(wv_from_bin.most_similar(\"apple\"))\n",
        "# ------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdQ018tjSSuT"
      },
      "source": [
        "#### <font color=\"red\">Write your answer here.</font>\n",
        "> -  \"mouse\" 这个词有两个含义：(1) 动物（老鼠）；(2) 电脑外设（鼠标）。在 top-10 中，rat, mice, rabbit, cat 对应动物含义；keyboard, cursor, trackball, joystick, clicks 对应电脑鼠标含义。\n",
        "> \n",
        "> -  bat, bank, spring, apple 的 top-10 都只体现了一个含义。这是因为 GloVe 给每个词只分配了一个向量。当一个词的某个含义在训练语料中远比其他含义常见时，这个唯一的向量就会被主导含义\"拉走\"。例如 \"apple\" 在现代大规模语料中作为公司名出现的频率远高于水果，所以向量几乎完全被科技公司含义占据。\"mouse\" 之所以成功，是因为它的两个含义（动物和电脑鼠标）在语料中都足够常见，使得向量落在了两个含义的\"中间地带\"。\n",
        "> \n",
        "> GloVe学到的是：$\\mathbf{u}_j^\\top\\mathbf{v}i \\approx \\log X{ij}$\n",
        "> \n",
        "> $X_{ij}$ 是所有语境中的共现总和\n",
        "> \n",
        "> 如果\"bank（银行）\"在语料中出现10000次，\"bank（河岸）\"只出现100次\n",
        "> \n",
        "> 那么这个词的向量会被高频义项主导\n",
        "> \n",
        "> - 解决方案：\n",
        ">     - 收集词的所有出现位置\n",
        ">     - 用上下文向量表示\"这个出现的语境\"\n",
        ">     - 聚类得到不同义项\n",
        ">     - 每个义项训练不同向量（bank#1, bank#2）\n",
        "> \n",
        "> 但标准GloVe没有这个机制，所以存在多义词混淆问题。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfeW-eK9SSuU"
      },
      "source": [
        "### Question 2.3: Synonyms & Antonyms (2 points) [code + written] \n",
        "\n",
        "When considering Cosine Similarity, it's often more convenient to think of Cosine Distance, which is simply 1 - Cosine Similarity.\n",
        "\n",
        "Find three words $(w_1,w_2,w_3)$ where $w_1$ and $w_2$ are synonyms and $w_1$ and $w_3$ are antonyms, but Cosine Distance $(w_1,w_3) <$ Cosine Distance $(w_1,w_2)$. \n",
        "\n",
        "As an example, $w_1$=\"happy\" is closer to $w_3$=\"sad\" than to $w_2$=\"cheerful\". Please find a different example that satisfies the above. Once you have found your example, please give a possible explanation for why this counter-intuitive result may have happened.\n",
        "\n",
        "You should use the the `wv_from_bin.distance(w1, w2)` function here in order to compute the cosine distance between two words. Please see the __[GenSim documentation](https://radimrehurek.com/gensim/models/keyedvectors.html#gensim.models.keyedvectors.FastTextKeyedVectors.distance)__ for further assistance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwlpPjpHSSuV",
        "outputId": "8c983677-b3d1-4423-d31c-da566cb522a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "同义词距离 distance(happy, cheerful) = 0.5172467231750488\n",
            "反义词距离 distance(happy, sad) = 0.4040136933326721\n"
          ]
        }
      ],
      "source": [
        "# ------------------\n",
        "# Write your implementation here.\n",
        "w1 = \"happy\"\n",
        "w2 = \"cheerful\"\n",
        "w3 = \"sad\"\n",
        "\n",
        "# 计算余弦距离（= 1 - 余弦相似度，越小越相似）\n",
        "d_synonym = wv_from_bin.distance(w1, w2)   # 同义词之间的距离\n",
        "d_antonym = wv_from_bin.distance(w1, w3)   # 反义词之间的距离\n",
        "\n",
        "print(f\"同义词距离 distance({w1}, {w2}) = {d_synonym}\")\n",
        "print(f\"反义词距离 distance({w1}, {w3}) = {d_antonym}\")\n",
        "\n",
        "# 确保反义词距离小于同义词距离\n",
        "assert d_antonym < d_synonym\n",
        "\n",
        "# ------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PeIHjTFMSSuV"
      },
      "source": [
        "#### <font color=\"red\">Write your answer here.</font>\n",
        "> 为什么反义词可能比同义词更近？\n",
        "> \n",
        "> 1. 上下文分布相似\n",
        "> \n",
        "> \"hot\" 和 \"cold\" 经常出现在相同的上下文\n",
        "> 例如：\"The water is [hot/cold]\", \"not hot but cold\"\n",
        "> 所以它们的共现模式 $P(w|hot)$ 和 $P(w|cold)$ 很相似\n",
        "> \n",
        "> 2. 同义词的语域差异\n",
        "> \n",
        "> \"happy\" 可能更口语化\n",
        "> \"cheerful\" 可能更正式/书面\n",
        "> 它们用在不同的语境，导致共现模式差异大\n",
        "> \n",
        "> 3. 连接到共现统计\n",
        "> \n",
        "> $P(cold|ice)$ 大，$P(hot|ice)$ 小\n",
        "> 但 \"hot\" 和 \"cold\" 在其他很多上下文中会一起被讨论\n",
        "> 整体的 $\\sum_k X_{hot,k}$ 和 $\\sum_k X_{cold,k}$ 的分布可能很相似"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxIDq26zSSuW"
      },
      "source": [
        "### Question 2.4: Analogies with Word Vectors [written] (1.5 points)\n",
        "Word vectors have been shown to *sometimes* exhibit the ability to solve analogies. \n",
        "\n",
        "As an example, for the analogy \"man : grandfather :: woman : x\" (read: man is to grandfather as woman is to x), what is x?\n",
        "\n",
        "In the cell below, we show you how to use word vectors to find x using the `most_similar` function from the __[GenSim documentation](https://radimrehurek.com/gensim/models/keyedvectors.html#gensim.models.keyedvectors.KeyedVectors.most_similar)__. The function finds words that are most similar to the words in the `positive` list and most dissimilar from the words in the `negative` list (while omitting the input words, which are often the most similar; see [this paper](https://www.aclweb.org/anthology/N18-2039.pdf)). The answer to the analogy will have the highest cosine similarity (largest returned numerical value)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0pC7H4VSSuY",
        "outputId": "a2e3a0c1-2621-4def-f00b-f3de583f86bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('grandmother', 0.7608445286750793),\n",
            " ('granddaughter', 0.7200808525085449),\n",
            " ('daughter', 0.7168302536010742),\n",
            " ('mother', 0.7151536345481873),\n",
            " ('niece', 0.7005682587623596),\n",
            " ('father', 0.6659888029098511),\n",
            " ('aunt', 0.6623409390449524),\n",
            " ('grandson', 0.6618767976760864),\n",
            " ('grandparents', 0.644661009311676),\n",
            " ('wife', 0.6445354223251343)]\n"
          ]
        }
      ],
      "source": [
        "# Run this cell to answer the analogy -- man : grandfather :: woman : x\n",
        "pprint.pprint(wv_from_bin.most_similar(positive=['woman', 'grandfather'], negative=['man']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVv8I9WwSSuZ"
      },
      "source": [
        "Let $m$, $g$, $w$, and $x$ denote the word vectors for `man`, `grandfather`, `woman`, and the answer, respectively. Using **only** vectors $m$, $g$, $w$, and the vector arithmetic operators $+$ and $-$ in your answer, what is the expression in which we are maximizing cosine similarity with $x$?\n",
        "\n",
        "Hint: Recall that word vectors are simply multi-dimensional vectors that represent a word. It might help to draw out a 2D example using arbitrary locations of each vector. Where would `man` and `woman` lie in the coordinate plane relative to `grandfather` and the answer?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlUKBqtHSSuZ"
      },
      "source": [
        "#### <font color=\"red\">Write your answer here.</font>\n",
        "\n",
        "构造的目标向量 $\\mathbf{t}$ 是：\n",
        "$$\\mathbf{t} = \\mathbf{x}_b - \\mathbf{x}_a + \\mathbf{x}_c$$\n",
        "\n",
        "然后在词表里找 $\\arg\\max_i \\cos(\\mathbf{t}, \\mathbf{x}_i)$\n",
        "\n",
        "cosine similarity 等价于\"只比较方向，不比较长度\"。词向量的长度常受词频等因素影响；类比更关心\"语义方向\"。所以使用余弦相似度\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rRgMca9SSua"
      },
      "source": [
        "### Question 2.5: Finding Analogies [code + written]  (1.5 points)\n",
        "a. For the previous example, it's clear that \"grandmother\" completes the analogy. But give an intuitive explanation as to why the `most_similar` function gives us words like \"granddaughter\", \"daughter\", or \"mother?\n",
        "\n",
        "解释grandmother之外的结果，为什么除了grandmother，还有granddaughter、daughter？"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgYQXazQSSua"
      },
      "source": [
        "#### <font color=\"red\">Write your answer here.</font>\n",
        "\n",
        "> 根据公式：\n",
        "> $$\\text{target} = \\text{grandfather} - \\text{man} + \\text{woman}$$\n",
        "> \n",
        "> 第一步：grandfather - man = ?\n",
        "> - 提取\"祖辈关系\"的语义\n",
        "> - 但也包含\"年长\"、\"家庭成员\"等特征\n",
        "> \n",
        "> 第二步：+ woman\n",
        "> - 加入\"女性\"特征\n",
        "> 结果：\n",
        "> - grandmother ✅（祖辈 + 女性）\n",
        "> - granddaughter（孙辈 + 女性，因为向量空间中\"家庭关系\"的维度接近）\n",
        "> - daughter（晚辈 + 女性）\n",
        "> - mother（长辈 + 女性）\n",
        "> \n",
        "> 结论：\n",
        "> \n",
        "> 向量空间中的\"语义维度\"不是完全正交的。维度太低会欠拟合（需要至少 gender + leadership 维度来表示 king/queen/man/woman）\n",
        "> \n",
        "> 即使是200维，也无法完美地把所有语义关系分离，所以会有\"语义泄漏\"。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9aAUXEISSub"
      },
      "source": [
        "b. Find an example of analogy that holds according to these vectors (i.e. the intended word is ranked top). In your solution please state the full analogy in the form x:y :: a:b. If you believe the analogy is complicated, explain why the analogy holds in one or two sentences.\n",
        "\n",
        "**Note**: You may have to try many analogies to find one that works!\n",
        "\n",
        "如果要找成功的类比，首先应该窗口的大小影响捕捉的关系类型：\n",
        "- 小窗口：句法关系（如辞行、时态）\n",
        "- 大窗口：语义关系（如国家、首都）\n",
        "\n",
        "GloVe通常用窗口大小约8，所以应该在语义类比上表现好。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "CRvYK2xifpq7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('queen', 0.6978678107261658),\n",
            " ('princess', 0.6081745028495789),\n",
            " ('monarch', 0.5889754891395569),\n",
            " ('throne', 0.5775108933448792),\n",
            " ('prince', 0.5750998258590698),\n",
            " ('elizabeth', 0.5463595986366272),\n",
            " ('daughter', 0.5399126410484314),\n",
            " ('kingdom', 0.5318052768707275),\n",
            " ('mother', 0.5168544054031372),\n",
            " ('crown', 0.5164473056793213)]\n",
            "[('quickly', 0.6525375843048096),\n",
            " ('finally', 0.5755026936531067),\n",
            " ('then', 0.5415216684341431),\n",
            " ('soon', 0.5269242525100708),\n",
            " ('turning', 0.5224605202674866),\n",
            " ('away', 0.521220862865448),\n",
            " ('turn', 0.5149972438812256),\n",
            " ('quietly', 0.5138120651245117),\n",
            " ('immediately', 0.5122365355491638),\n",
            " ('into', 0.5081465244293213)]\n",
            "[('rome', 0.7585406303405762),\n",
            " ('milan', 0.6850501298904419),\n",
            " ('italian', 0.6647830009460449),\n",
            " ('venice', 0.6126590967178345),\n",
            " ('turin', 0.5984683036804199),\n",
            " ('florence', 0.5939043760299683),\n",
            " ('bologna', 0.5863773822784424),\n",
            " ('naples', 0.5858203172683716),\n",
            " ('prohertrib', 0.5709968209266663),\n",
            " ('genoa', 0.5506733655929565)]\n"
          ]
        }
      ],
      "source": [
        "# For example: x, y, a, b = (\"\", \"\", \"\", \"\")\n",
        "# ------------------\n",
        "# Write your implementation here.\n",
        "\n",
        "# 性别类比（语义）\n",
        "pprint.pprint(wv_from_bin.most_similar(positive=['king', 'woman'], negative=['man']))\n",
        "\n",
        "# 国家-首都（语义）\n",
        "# pprint.pprint(wv_from_bin.most_similar(positive=['france', 'paris'], negative=['italy']))\n",
        "\n",
        "# 词性类比（句法）\n",
        "pprint.pprint(wv_from_bin.most_similar(positive=['quick', 'slowly'], negative=['slow']))\n",
        "\n",
        "x, y, a, b = (\"france\", \"paris\", \"italy\", \"rome\")\n",
        "\n",
        "pprint.pprint(wv_from_bin.most_similar(positive=[a, y], negative=[x]))\n",
        "\n",
        "# ------------------\n",
        "\n",
        "# Test the solution\n",
        "assert wv_from_bin.most_similar(positive=[a, y], negative=[x])[0][0] == b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3QlPqAwSSub"
      },
      "source": [
        "#### <font color=\"red\">Write your answer here.</font>\n",
        "\n",
        "> france : paris :: italy : rome\n",
        ">\n",
        "> This analogy holds because the relationship between France and Paris (country to its capital) is the same as the relationship between Italy and Rome. The word vectors successfully capture this \"country-capital\" relationship as a consistent vector offset, so subtracting the country vector and adding another country's vector correctly points to that country's capital."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwgcEywwSSuc"
      },
      "source": [
        "### Question 2.6: Incorrect Analogy [code + written] (1.5 points)\n",
        "a. Below, we expect to see the intended analogy \"hand : glove :: foot : **sock**\", but we see an unexpected result instead. Give a potential reason as to why this particular analogy turned out the way it did?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-ykWoJoSSuc",
        "outputId": "60fa3812-3e62-429e-c309-349463c75f9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('45,000-square', 0.4922032654285431),\n",
            " ('15,000-square', 0.4649604558944702),\n",
            " ('10,000-square', 0.4544755816459656),\n",
            " ('6,000-square', 0.44975775480270386),\n",
            " ('3,500-square', 0.444133460521698),\n",
            " ('700-square', 0.44257497787475586),\n",
            " ('50,000-square', 0.4356396794319153),\n",
            " ('3,000-square', 0.43486514687538147),\n",
            " ('30,000-square', 0.4330596923828125),\n",
            " ('footed', 0.43236875534057617)]\n"
          ]
        }
      ],
      "source": [
        "pprint.pprint(wv_from_bin.most_similar(positive=['foot', 'glove'], negative=['hand']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zn4ruS8MSSud"
      },
      "source": [
        "#### <font color=\"red\">Write your answer here.</font>\n",
        "\n",
        "GloVe学到的是 $\\mathbf{u}_j^\\top\\mathbf{v}i \\approx \\log X{ij}$\n",
        "\n",
        "> 1. 在语料中，\"glove\" 和 \"foot\" 几乎不会一起出现\n",
        "> \n",
        ">     foot + glove 的向量加法产生的可能是\"防护装备\"的语义\n",
        "> \n",
        "> 2. \"sock\" 可能更多出现在日常用语、穿衣场景\n",
        "> \n",
        ">     \"glove\" 可能更多出现在运动、寒冷天气场景\n",
        ">     \n",
        ">     它们的 $X_{sock,k}$ 和 $X_{glove,k}$ 分布差异大\n",
        "> \n",
        "> 3. 期望的答案是 \"sock\"，但结果全是类似 \"45,000-square\"、\"15,000-square\" 这样的词。\n",
        "> \n",
        ">     这是因为 foot + glove - hand 计算出来的向量，恰好被拉向了 \"square foot\"（平方英尺） 这个方向：\n",
        "> \n",
        ">     foot 在语料中大量出现在 度量单位 的语境里（如 \"a 45,000-square-foot building\"） \n",
        "> \n",
        ">     这些 \"XX,000-square\" 其实是 \"XX,000-square-foot\" 在分词后的产物\n",
        "> \n",
        ">     这个度量单位含义压过了\"脚\"的含义所以向量运算的结果指向了\"平方英尺\"相关的词，而不是\"袜子\"。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1gHyZt0SSud"
      },
      "source": [
        "b. Find another example of analogy that does *not* hold according to these vectors. In your solution, state the intended analogy in the form x:y :: a:b, and state the **incorrect** value of b according to the word vectors (in the previous example, this would be **'45,000-square'**)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "ms-DTC8_ftiA"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('you', 0.48027661442756653),\n",
            " ('how', 0.45332497358322144),\n",
            " (\"'d\", 0.4527038335800171),\n",
            " ('cover', 0.4514838755130768),\n",
            " ('tell', 0.44960734248161316),\n",
            " ('whatever', 0.44567203521728516),\n",
            " ('piece', 0.44481360912323),\n",
            " (\"'ll\", 0.43800321221351624),\n",
            " ('done', 0.430388480424881),\n",
            " ('writing', 0.428756982088089)]\n"
          ]
        }
      ],
      "source": [
        "# For example: x, y, a, b = (\"\", \"\", \"\", \"\")\n",
        "# ------------------\n",
        "# Write your implementation here.\n",
        "# x, y, a, b = (\"curry\", \"indian\", \"pizza\", \"italian\")\n",
        "x, y, a, b = (\"pen\", \"write\", \"knife\", \"cut\")\n",
        "\n",
        "# ------------------\n",
        "pprint.pprint(wv_from_bin.most_similar(positive=[a, y], negative=[x]))\n",
        "assert wv_from_bin.most_similar(positive=[a, y], negative=[x])[0][0] != b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4x0EHjeSSue"
      },
      "source": [
        "#### <font color=\"red\">Write your answer here.</font>\n",
        "\n",
        "> 设计的类比是：curry : indian :: pizza : italian\n",
        "> \n",
        "> 期望输出italian，但输出的是india\n",
        "> \n",
        "> pen:write :: knife:? （期望 cut）, 输出： you"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvlycXN-SSuf"
      },
      "source": [
        "### Question 2.7: Guided Analysis of Bias in Word Vectors [written] (1 point)\n",
        "\n",
        "It's important to be cognizant of the biases (gender, race, sexual orientation etc.) implicit in our word embeddings. Bias can be dangerous because it can reinforce stereotypes through applications that employ these models.\n",
        "\n",
        "Run the cell below, to examine (a) which terms are most similar to \"man\" and \"profession\" and most dissimilar to \"woman\" and (b) which terms are most similar to \"woman\" and \"profession\" and most dissimilar to \"man\". Point out the difference between the list of female-associated words and the list of male-associated words, and explain how it is reflecting gender bias."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XggWA4MhSSuf",
        "outputId": "534a694b-f4fa-479e-9e7c-12b17db3abb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('reputation', 0.5250176787376404),\n",
            " ('professions', 0.5178037881851196),\n",
            " ('skill', 0.49046966433525085),\n",
            " ('skills', 0.49005505442619324),\n",
            " ('ethic', 0.4897659420967102),\n",
            " ('business', 0.487585186958313),\n",
            " ('respected', 0.485920250415802),\n",
            " ('practice', 0.482104629278183),\n",
            " ('regarded', 0.4778572916984558),\n",
            " ('life', 0.4760662019252777)]\n",
            "\n",
            "[('professions', 0.5957457423210144),\n",
            " ('practitioner', 0.49884122610092163),\n",
            " ('teaching', 0.48292139172554016),\n",
            " ('nursing', 0.48211804032325745),\n",
            " ('vocation', 0.4788965880870819),\n",
            " ('teacher', 0.47160351276397705),\n",
            " ('practicing', 0.46937814354896545),\n",
            " ('educator', 0.46524327993392944),\n",
            " ('physicians', 0.4628995358943939),\n",
            " ('professionals', 0.4601394236087799)]\n"
          ]
        }
      ],
      "source": [
        "# Run this cell\n",
        "# Here `positive` indicates the list of words to be similar to and `negative` indicates the list of words to be\n",
        "# most dissimilar from.\n",
        "\n",
        "pprint.pprint(wv_from_bin.most_similar(positive=['man', 'profession'], negative=['woman']))\n",
        "print()\n",
        "pprint.pprint(wv_from_bin.most_similar(positive=['woman', 'profession'], negative=['man']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4g6KbsYSSuh"
      },
      "source": [
        "#### <font color=\"red\">Write your answer here.</font>\n",
        "\n",
        "> 女性关联的职业倾向于具体的服务/教育类职业（teaching, nursing, educator），而男性关联的词更偏向抽象的能力、声望和商业（business, reputation, respected, skill），暗示男性与权威/成就挂钩。\n",
        "> \n",
        "> 这反映了训练语料（Wikipedia、新闻）中的性别偏见——女性更常在\"教师\"\"护士\"等语境中被提及，男性更常在\"商业\"\"受尊敬\"\"技能\"等语境中被提及。GloVe 把这种社会层面的刻板印象编码进了词向量中。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxJmnS6lSSui"
      },
      "source": [
        "### Question 2.8: Independent Analysis of Bias in Word Vectors [code + written]  (1 point)\n",
        "\n",
        "Use the `most_similar` function to find another pair of analogies that demonstrates some bias is exhibited by the vectors. Please briefly explain the example of bias that you discover."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZoDheIfSSui",
        "outputId": "f45fef83-ee36-4ef1-b970-775c3b40c515"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('investigations', 0.5599403381347656),\n",
            " ('crimes', 0.5473870038986206),\n",
            " ('investigation', 0.5373427867889404),\n",
            " ('criminals', 0.5174946188926697),\n",
            " ('antitrust', 0.5164338946342468),\n",
            " ('crime', 0.5132272839546204),\n",
            " ('prosecutors', 0.5110832452774048),\n",
            " ('prosecution', 0.507327675819397),\n",
            " ('enforcement', 0.5033372044563293),\n",
            " ('charges', 0.4930346608161926)]\n",
            "\n",
            "[('crimes', 0.5542032718658447),\n",
            " ('crime', 0.5206238627433777),\n",
            " ('convicted', 0.5133807063102722),\n",
            " ('murder', 0.5020079612731934),\n",
            " ('prosecution', 0.5004827976226807),\n",
            " ('charges', 0.4813272953033447),\n",
            " ('defendant', 0.48000574111938477),\n",
            " ('defendants', 0.47705507278442383),\n",
            " ('trial', 0.4734346270561218),\n",
            " ('charged', 0.4717729985713959)]\n"
          ]
        }
      ],
      "source": [
        "# ------------------\n",
        "# Write your implementation here.\n",
        "# 方向1：与 european + criminal 相似，与 african 不相似\n",
        "pprint.pprint(wv_from_bin.most_similar(positive=['european', 'criminal'], negative=['african']))\n",
        "print()\n",
        "# 方向2：与 african + criminal 相似，与 european 不相似\n",
        "pprint.pprint(wv_from_bin.most_similar(positive=['african', 'criminal'], negative=['european']))\n",
        "\n",
        "# ------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGOlmtJoSSuj"
      },
      "source": [
        "#### <font color=\"red\">Write your answer here.</font>\n",
        "\n",
        "> 当 \"european\" 与 \"criminal\" 关联时，top-10 中出现的词更多是调查和执法相关的词（如 investigations, prosecutors, enforcement），以及白领犯罪（antitrust）；而当 \"african\" 与 \"criminal\" 关联时，出现了更多暴力犯罪（murder）和被审判/被定罪相关的词（convicted, defendant, charged, trial）。\n",
        ">\n",
        "> 这反映了词向量中的种族偏见：european 更多被关联到法律体系的执法者一侧，而 african 更多被关联到被告/罪犯一侧，且涉及更严重的犯罪类型。这种偏见源自训练语料（新闻报道等）中对不同种族在犯罪话题上的不平等叙述。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eK2XVWzmSSuk"
      },
      "source": [
        "### Question 2.9: Thinking About Bias [written] (2 points)\n",
        "\n",
        "a. Give one explanation of how bias gets into the word vectors. Briefly describe a real-world example that demonstrates this source of bias. Your real-world example should be focused on word vectors, as opposed to bias in other AI systems (e.g., ChatGPT)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19pM85fCSSuk"
      },
      "source": [
        "#### <font color=\"red\">Write your answer here.</font>\n",
        "\n",
        ">偏见通过训练语料进入词向量。词向量是从大规模文本的共现统计中学习的——GloVe 的优化目标\n",
        ">使得向量点积近似等于 log(共现次数)。如果语料本身包含社会偏见，这种偏见就会被编码进向量中。\n",
        ">\n",
        ">真实例子：在新闻语料中，\"doctor\"与\"he\"的共现次数远高于与\"she\"的共现次数\n",
        ">（因为新闻中描写男性医生的报道更多）。假设 $X_{doctor,he}$ = 1000，$X_{doctor,she}$ = 100，\n",
        ">那么训练后 $v_{doctor}^T u_{he}$ ≈ log(1000) ≈ 6.9，而 $v_{doctor}^T u_{she}$ ≈ log(100) ≈ 4.6。\n",
        ">这导致\"doctor\"在向量空间中离\"male\"更近。如果将这样的词向量用于简历筛选系统，\n",
        ">可能会不公平地倾向于将男性候选人与医生岗位匹配。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILYqJZ7ASSul"
      },
      "source": [
        "b. What is one method you can use to mitigate bias exhibited by word vectors? Briefly describe a real-world example that demonstrates this method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnJaAB7mSSul"
      },
      "source": [
        "\n",
        "#### <font color=\"red\">Write your answer here.</font>\n",
        ">一种方法是后处理去偏（Post-processing Debiasing，Bolukbasi et al. 2016）。\n",
        ">具体做法是：\n",
        ">1. 用已知的性别词对（如 he-she、man-woman）识别出向量空间中的\"性别方向\"\n",
        ">2. 对于不应有性别倾向的词（如 doctor、nurse、engineer），\n",
        ">   将它们在\"性别方向\"上的分量投影去除，使其变为零\n",
        ">\n",
        ">真实例子：Bolukbasi et al. 在 2016 年的研究中对 Google News 训练的 word2vec 向量\n",
        ">应用了这种方法。处理前，\"computer programmer\"与\"man\"的关联度远高于\"woman\"；\n",
        ">处理后，这类职业词在性别方向上变为中性，不再偏向任何一方。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzh3eEmZSSum"
      },
      "source": [
        "# <font color=\"blue\"> Submission Instructions</font>\n",
        "\n",
        "1. Click the Save button at the top of the Jupyter Notebook.\n",
        "2. Select Cell -> All Output -> Clear. This will clear all the outputs from all cells (but will keep the content of all cells). \n",
        "2. Select Cell -> Run All. This will run all the cells in order, and will take several minutes.\n",
        "3. Once you've rerun everything, select File -> Download as -> PDF via LaTeX (If you have trouble using \"PDF via LaTex\", you can also save the webpage as pdf. <font color='blue'> Make sure all your solutions especially the coding parts are displayed in the pdf</font>, it's okay if the provided codes get cut off because lines are not wrapped in code cells).\n",
        "4. Look at the PDF file and make sure all your solutions are there, displayed correctly. The PDF is the only thing your graders will see!\n",
        "5. Submit your PDF on Gradescope."
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "cs224n",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
